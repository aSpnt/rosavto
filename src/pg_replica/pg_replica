#!/usr/bin/env python

# -*- coding: utf-8 -*-

import re
import os
import sys
import glob
import fcntl
import uuid
import base64
import codecs
import datetime
import argparse
import logging
import ConfigParser

import psycopg2
import psycopg2.extensions

import requests


psycopg2.extensions.register_type(psycopg2.extensions.UNICODE)
psycopg2.extensions.register_type(psycopg2.extensions.UNICODEARRAY)


logger = logging.getLogger('pg_replica')
pid_file = 'pg_replica.pid'


class DbError(Exception):

    def __init__(self, message, query=None):
        self.message = unicode(message, 'utf-8')
        self.query = (unicode(query, 'utf-8') if query is not None else None)

    def __str__(self):
        return 'MESSAGE: %s\nQUERY: %s' % (self.message, self.query)


class PgDB:

    rep_schema = 'public'
    rep_table = 'rep_log'

    def __init__(self, host=None, port=None, dbname=None, user=None,
                 passwd=None):

        self.logger = logging.getLogger('pg_replica')
        self.re_ident_ok = re.compile(r"^\w+$")
        self.re_is_integer = re.compile('int[0-9]')
        self.re_is_float = re.compile('float[0-9]')

        self.host = host
        self.port = port
        self.dbname = dbname
        self.user = user
        self.passwd = passwd

        if self.dbname == '' or self.dbname is None:
            self.dbname = self.user

        try:
            self.con = psycopg2.connect(self.con_info())
        except psycopg2.OperationalError, e:
            self.logger.debug(e.message)
            raise DbError(e.message)

        self.has_postgis = self.check_postgis()
        self.logger.debug('PostGIS enabled: %s' % self.has_postgis)

    def con_info(self):
        con_str = ''
        if self.host:
            con_str += "host='%s' " % self.host
        if self.port:
            con_str += 'port=%d ' % self.port
        if self.dbname:
            con_str += "dbname='%s' " % self.dbname
        if self.user:
            con_str += "user='%s' " % self.user
        if self.passwd:
            con_str += "password='%s' " % self.passwd
        return con_str

    def check_postgis(self):
        c = self.con.cursor()
        self._exec_sql(c,
            "SELECT COUNT(*) FROM pg_proc WHERE proname = 'postgis_version'")
        return c.fetchone()[0] > 0

    def list_geotables(self, schema=None):
        c = self.con.cursor()

        if schema:
            schema_where = " AND nspname = '%s' " % self._quote_str(schema)
        else:
            schema_where = \
                " AND (nspname != 'information_schema' AND nspname !~ 'pg_') "

        if not self.has_postgis:
            sql = '''SELECT pg_class.relname, pg_namespace.nspname,
                            pg_class.relkind, pg_get_userbyid(relowner),
                            reltuples, relpages, NULL, NULL, NULL, NULL
                  FROM pg_class
                  JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace
                  WHERE pg_class.relkind IN ('v', 'r') ''' \
                  + schema_where + 'ORDER BY nspname, relname'
        else:
            sql = '''SELECT pg_class.relname, pg_namespace.nspname,
                            pg_class.relkind, pg_get_userbyid(relowner),
                            reltuples, relpages, pg_attribute.attname,
                            pg_attribute.atttypid::regtype, NULL, NULL
                  FROM pg_class
                  JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace
                  LEFT OUTER JOIN pg_attribute ON
                      pg_attribute.attrelid = pg_class.oid AND
                      (pg_attribute.atttypid = 'geometry'::regtype
                      OR pg_attribute.atttypid IN
                          (SELECT oid FROM pg_type
                           WHERE typbasetype='geometry'::regtype))
                  WHERE pg_class.relkind IN ('v', 'r') ''' \
                  + schema_where + 'ORDER BY nspname, relname, attname'

        self._exec_sql(c, sql)
        items = c.fetchall()

        if self.has_postgis:
            sql = '''SELECT relname, nspname, relkind,
                            pg_get_userbyid(relowner), reltuples, relpages,
                            geometry_columns.f_geometry_column,
                            geometry_columns.type,
                            geometry_columns.coord_dimension,
                            geometry_columns.srid
                  FROM pg_class
                  JOIN pg_namespace ON relnamespace=pg_namespace.oid
                  LEFT OUTER JOIN geometry_columns ON
                      relname=f_table_name AND nspname=f_table_schema
                  WHERE (relkind = 'r' or relkind='v') ''' \
                  + schema_where + 'ORDER BY nspname, relname, \
                  f_geometry_column'
            self._exec_sql(c, sql)

            for (i, geo_item) in enumerate(c.fetchall()):
                if geo_item[7]:
                    items[i] = geo_item

        return items

    def get_table_fields(self, table, schema=None):
        c = self.con.cursor()
        schema_where = (" AND nspname='%s' "
                        % self._quote_str(schema) if schema is not None else ''
                       )
        sql = '''SELECT a.attnum AS ordinal_position,
                        a.attname AS column_name,
                        t.typname AS data_type,
                        a.attlen AS char_max_len,
                        a.atttypmod AS modifier,
                        a.attnotnull AS notnull,
                        a.atthasdef AS hasdefault,
                        adef.adsrc AS default_value
              FROM pg_class c
              JOIN pg_attribute a ON a.attrelid = c.oid
              JOIN pg_type t ON a.atttypid = t.oid
              JOIN pg_namespace nsp ON c.relnamespace = nsp.oid
              LEFT JOIN pg_attrdef adef ON adef.adrelid = a.attrelid
                  AND adef.adnum = a.attnum
              WHERE
                  c.relname = '%s' %s AND
                  a.attnum > 0
              ORDER BY a.attnum''' % (self._quote_str(table), schema_where)

        self._exec_sql(c, sql)
        attrs = c.fetchall()
        return attrs

    def register_table(self, schema, table):
        if not self.create_replog_table():
            return False

        table_name = self._table_name(schema, table)
        repl_table = self._table_name(self.rep_schema, self.rep_table)

        fields = self.get_table_fields(table, schema)
        has_uuid = len(
            [f for f in fields if f[1] == 'uniq_uid' and \
                                  f[2] == 'varchar']) > 0
        if not has_uuid:
            self.logger.error('Can not register table "%s" because it has '
                              'no "uniq_uid" field of type "varchar".'
                              % table_name)
            return False

        proc_name = table + '_rep'

        sql = '''CREATE OR REPLACE FUNCTION %s() RETURNS trigger AS $%s$
                     BEGIN
                         IF (TG_OP = 'INSERT') THEN
                             INSERT INTO %s(
                                 table_name, operation, stamp, uid)
                             VALUES('%s', 2, current_timestamp, NEW.uniq_uid);
                             RETURN NEW;
                         ELSIF (TG_OP = 'UPDATE') THEN
                             INSERT INTO %s(
                                 table_name, operation, stamp, uid)
                             VALUES('%s', 3, current_timestamp, OLD.uniq_uid);
                             RETURN NEW;
                         ELSIF (TG_OP = 'DELETE') THEN
                             INSERT INTO %s(
                                 table_name, operation, stamp, uid)
                             VALUES('%s', 1, current_timestamp, OLD.uniq_uid);
                             RETURN NEW;
                         END IF;
                     END;
                 $%s$ LANGUAGE plpgsql;
                 CREATE TRIGGER %s AFTER INSERT OR UPDATE OR DELETE
                     ON %s FOR EACH ROW EXECUTE PROCEDURE %s();
              ''' % (proc_name, proc_name,
                     repl_table, table_name,
                     repl_table, table_name,
                     repl_table, table_name,
                     proc_name,
                     proc_name,
                     table_name, proc_name)
        self._exec_sql_and_commit(sql)
        return True

    def prepare_changes(self, timestamp, boundary, url_field, bus, bus_user,
                        bus_passwd, local_addr):
        records = self.list_changes(timestamp)

        data = dict()
        for table, uid in records:
            if table not in data:
                data[table] = [uid]
            else:
                data[table].append(uid)

        repl_table = self._table_name(self.rep_schema, self.rep_table)

        c = self.con.cursor()

        for full_table_name, uids in data.iteritems():
            schema = full_table_name.split('.')[0]
            table = full_table_name.split('.')[1]

            ddl = self.dump_table(schema, table)
            if ddl == '':
                self.logger.critical('Can not get DDL for table "%s".' % table)
                return

            fields = self.get_table_fields(table, schema)
            plain_field_list = []
            select_field_list = []
            for count, field in enumerate(fields):
                field_name = field[1]
                field_type = field[2]
                if field_name == 'ogc_fid':
                    continue
                if field_type in ['geometry']:
                    select_field_list.append(
                        "encode(ST_AsEWKB(%s), 'hex')" % field_name)
                    plain_field_list.append(field_name)
                    geom_name = field_name
                    continue
                plain_field_list.append(field_name)
                select_field_list.append(field_name)

            geom_index = plain_field_list.index(geom_name)

            for uid in uids:
                sql = '''SELECT *
                         FROM %s
                         WHERE uid='%s'
                         ORDER BY stamp DESC
                         LIMIT 1;
                      ''' % (repl_table, uid)
                self._exec_sql(c, sql)
                result = c.fetchone()

                operation = result[1]

                if operation != 1:
                    sql = "SELECT %s FROM %s WHERE uniq_uid='%s';" % (
                        ', '.join(self._quote_field_list(select_field_list)),
                        full_table_name, uid)
                    self._exec_sql(c, sql)
                    values = c.fetchone()

                    value_list = []
                    for (count, value) in enumerate(values):
                        if count == geom_index:
                            value_list.append(
                                "ST_GeomFromEWKB(decode('%s', 'hex'))" % value)
                            continue
                        value_list.append(value)

                    values = self.populate_values(
                        fields, value_list, plain_field_list)

                if operation == 1:
                    self.logger.debug('Found DELETE operation.')

                    sql = "DELETE FROM %s WHERE uniq_uid='%s'" % (
                        full_table_name, uid)
                    self.logger.debug(
                        'Replication SQL: %s' % ' '.join(sql.split()))
                elif operation == 2:
                    self.logger.debug('Found INSERT operation.')

                    sql = 'INSERT INTO %s(%s) VALUES(%s);' % (
                        full_table_name,
                        ', '.join(self._quote_field_list(plain_field_list)),
                        values)
                    self.logger.debug(
                        'Replication SQL: %s' % ' '.join(sql.split()))
                elif operation == 3:
                    self.logger.debug('Found UPDATE operation.')

                    sql = '''UPDATE %s
                           SET (%s) = (%s)
                           WHERE uniq_uid='%s';
                        ''' % (full_table_name,
                               ', '.join(self._quote_field_list(plain_field_list)),
                               values,
                               uid)
                    self.logger.debug(
                        'Replication SQL: %s' % ' '.join(sql.split()))

                encoded_table = base64.urlsafe_b64encode(full_table_name)

                ddl = ' '.join(ddl.split()).encode('utf-8')
                encoded_ddl = base64.urlsafe_b64encode(ddl)

                sql = ' '.join(sql.split()).encode('utf-8')
                encoded_sql = base64.urlsafe_b64encode(sql)

                headers = {'content-type': 'text/xml', 'Accept': 'text/xml'}
                auth = (bus_user, bus_passwd)

                sql = '''SELECT %s
                         FROM %s
                         WHERE ST_Intersects(wkb_geometry,
                             (SELECT wkb_geometry
                              FROM %s
                              WHERE uniq_uid = '%s'))
                      ''' % (url_field, boundary, full_table_name, uid)
                self._exec_sql(c, sql)
                urls = c.fetchall()

                if urls is None or len(urls) == 0:
                    self.logger.error('No intersections with zones found.')
                    continue

                for url in urls:
                    xml = self._create_message(encoded_table, encoded_ddl, encoded_sql, local_addr, url)

                    r = requests.post(bus, data=xml, headers=headers, auth=auth)
                    if r.status_code == 202:
                        self.logger.debug('Server responce: %s' % r.status_code)
                    else:
                        self.logger.error('Server responce: %s' % r.status_code)
                        self.logger.error('Error message: %s' % r.text)

        self.clear_old_records(timestamp)

    def apply_changes(self, directory, bus, bus_user, bus_passwd):
        headers = {'content-type': 'text/xml', 'Accept': 'text/xml'}
        auth = (bus_user, bus_passwd)

        file_list = sorted(glob.glob(os.path.join(directory, '*.changes')))
        self.logger.debug('Found %s changesets.' % len(file_list))

        cfg = ConfigParser.SafeConfigParser()

        for file_name in file_list:
            self.logger.debug('Processing file: "%s".' % file_name)
            cfg.readfp(codecs.open(file_name, encoding='utf-8'))

            table = cfg.get('changeset', 'table')
            ddl = cfg.get('changeset', 'ddl')
            sql = cfg.get('changeset', 'sql')
            src = cfg.get('changeset', 'src')
            dst = cfg.get('changeset', 'dst')

            full_table_name = base64.urlsafe_b64decode(table.encode('utf-8'))
            self.logger.debug('Decoded table name: %s' % full_table_name)
            ddl = base64.urlsafe_b64decode(ddl.encode('utf-8'))
            self.logger.debug('Decoded table DDL: %s' % ddl)
            sql = base64.urlsafe_b64decode(sql.encode('utf-8')).decode('utf-8')
            self.logger.debug('Decoded table SQL: %s' % sql)

            schema = full_table_name.split('.')[0]
            table = full_table_name.split('.')[1]

            if not self._table_exists(schema, table):
                self.logger.debug('Table "%s" not found. Try to create it.' %
                    table_name)
                try:
                    self._exec_sql_and_commit(ddl)
                except DbError, e:
                    err = base64.urlsafe_b64encode(sys.exc_info()[0])
                    xml = self._create_message(table, ddl, sql, dst, src, err)

                    r = requests.post(bus, data=xml, headers=headers, auth=auth)
                    if r.status_code == 202:
                        self.logger.debug('Server responce: %s' % r.status_code)
                    else:
                        self.logger.error('Server responce: %s' % r.status_code)
                        self.logger.error('Error message: %s' % r.text)

            try:
                self._exec_sql_and_commit(sql)
            except DbError, e:
                err = base64.urlsafe_b64encode(sys.exc_info()[0])
                xml = self._create_message(table, ddl, sql, dst, src, err)

                r = requests.post(bus, data=xml, headers=headers, auth=auth)
                if r.status_code == 202:
                    self.logger.debug('Server responce: %s' % r.status_code)
                else:
                    self.logger.error('Server responce: %s' % r.status_code)
                    self.logger.error('Error message: %s' % r.text)

            os.remove(file_name)
            self.logger.debug('File "%s" processed and removed' % file_name)

        directory = os.path.join(directory, 'failed')
        if os.path.exists(directory) and os.path.isdir(directory):
            file_list = sorted(glob.glob(os.path.join(directory, '*.changes')))
            self.logger.debug('Found %s failed changesets.' % len(file_list))

            for file_name in file_list:
                self.logger.debug('Processing file: "%s".' % file_name)
                cfg.readfp(codecs.open(file_name, encoding='utf-8'))

                err = base64.urlsafe_b64decode(
                    cfg.get('misc', 'error').encode('utf-8'))
                self.logger.debug('Error message: %s' % err)
                dst = base64.urlsafe_b64decode(
                    cfg.get('changeset', 'dst').encode('utf-8'))
                self.logger.debug('Node address: %s' % dst)
                self.logger.waring('REMOTE ERROR: %s - %s. File %s' % (dst, err, file_name))

                try:
                    os.rename(file_name, file_name + '.old')
                except Exception, e:
                    self.logger.error('Failed to rename file: %s' % sys.exc_info()[0])


    def dump_table(self, schema, table):
        c = self.con.cursor()

        full_table_name = self._table_name(schema, table)
        table_name = self._quote_str(table)

        ddl = ''

        sql = "SELECT '%s'::regclass::oid" % full_table_name
        self._exec_sql(c, sql)
        table_oid = c.fetchone()[0]

        if table_oid is None:
            self.logger.critical("Can not resolve table name '%s' to OID." %
                                 table_name)
            return ''

        sql = '''SELECT c.relname AS seq,
                        t.relname AS tab,
                        a.attname AS col
                 FROM pg_class c
                   JOIN pg_depend d on d.objid = c.oid AND
                        d.classid='pg_class'::regclass AND
                        d.refclassid='pg_class'::regclass
                   JOIN pg_class t on t.oid = d.refobjid
                   JOIN pg_namespace n on n.oid = t.relnamespace
                   JOIN pg_attribute a on a.attrelid = t.oid AND
                        a.attnum=d.refobjsubid
                   WHERE c.relkind='S' AND
                         d.deptype='a' AND
                         t.oid = %s
              ''' % table_oid

        self._exec_sql(c, sql)
        sequences = c.fetchall()

        alter_stmt = ''
        if sequences is not None and len(sequences) != 0:
            for s in sequences:
                res = self.dump_sequence(schema, s)
                ddl += res[0] + '\n'
                alter_stmt += res[1] + '\n'

        ddl += 'CREATE TABLE %s (' % table_name

        sql = '''SELECT a.attname as atname, a.attnotnull as notnull,
                        a.atthasdef as hasdef,
                        format_type(a.atttypid, a.atttypmod) as typedefn,
                        ad.adsrc as deflt
                 FROM pg_attribute a
                 LEFT OUTER JOIN pg_type t ON a.atttypid = t.oid
                 LEFT OUTER JOIN pg_attrdef ad ON (ad.adrelid=a.attrelid AND
                                                   ad.adnum=a.attnum)
                 WHERE a.attrelid = %s AND
                       a.attnum > 0
                 ORDER BY attnum
              ''' % table_oid
        self._exec_sql(c, sql)
        fields = c.fetchall()
        for field in fields:
            ddl += '"%s" %s' % (field[0], field[3])
            if field[1]:
                ddl += ' NOT NULL'
            if field[2]:
                ddl += ' DEFAULT %s' % field[4]
            ddl = ddl.strip() + ', '

        sql = '''SELECT relname, oid
                 FROM pg_class
                 WHERE oid = (SELECT indexrelid
                              FROM pg_index i
                              WHERE i.indisprimary AND i.indrelid = %s)
              ''' % table_oid
        self._exec_sql(c, sql)
        pkey = c.fetchone()
        if pkey is not None:
            ddl += 'CONSTRAINT %s PRIMARY KEY (' % pkey[0]
            sql = '''SELECT attname
                     FROM pg_attribute
                     WHERE attrelid = %s
                  ''' % pkey[1]
            self._exec_sql(c, sql)
            fields = c.fetchall()
            for field in fields:
                ddl += '%s, ' % field
            ddl = ddl[:-2] + '));\n'

        ddl += alter_stmt

        sql = '''SELECT pg_catalog.pg_get_indexdef(i.indexrelid, 0, true)
                 FROM pg_catalog.pg_class c,
                      pg_catalog.pg_class c2,
                      pg_catalog.pg_index i
                 WHERE c.oid = %s AND
                       c.oid = i.indrelid AND
                       i.indexrelid = c2.oid AND
                       i.indisprimary = FALSE
                 ORDER BY i.indisunique DESC, c2.relname
              ''' % table_oid
        self._exec_sql(c, sql)
        indices = c.fetchall()
        for idx in indices:
            ddl += idx[0] + '\n'

        self.logger.debug('DDL for relation "%s": %s' % (table_name, ddl))
        return ddl

    def dump_sequence(self, schema, sequence):
        seqMax = sys.maxint
        seqMin = -seqMax - 1

        full_sequence_name = '%s.%s' % (schema, sequence[0])

        c = self.con.cursor()

        sql = '''SELECT sequence_name,
                        0 AS start_value,
                        increment_by,
                        CASE WHEN increment_by > 0 AND max_value = %s THEN NULL
                             WHEN increment_by < 0 AND max_value = -1 THEN NULL
                             ELSE max_value
                        END AS max_value,
                        CASE WHEN increment_by > 0 AND min_value = 1 THEN NULL
                             WHEN increment_by < 0 AND min_value = %s THEN NULL
                             ELSE min_value
                        END AS min_value,
                        cache_value,
                        is_cycled
                 FROM %s
              ''' % (seqMax, seqMin, full_sequence_name)

        self._exec_sql(c, sql)
        seq = c.fetchone()

        maxValue = 'NO MAXVALUE' if seq[3] is None else 'MAXVALUE %s' % seq[3]
        minValue = 'NO MINVALUE' if seq[3] is None else 'MINVALUE %s' % seq[4]
        cycle = '' if not seq[6] else 'CYCLE'

        ddl = '''CREATE SEQUENCE %s
                 START WITH %s
                 INCREMENT BY %s
                 %s
                 %s
                 CACHE %s
                 %s;\n
              ''' % (seq[0],
                     seq[1],
                     seq[2],
                     minValue,
                     maxValue,
                     seq[5],
                     cycle
                    )

        ddl2 = '''ALTER SEQUENCE %s OWNED BY %s.%s;''' % (sequence[0],
            sequence[1], sequence[2])

        return (' '.join(ddl.split()), ddl2)

    def list_changes(self, timestamp):
        c = self.con.cursor()

        table_name = self._table_name(self.rep_schema, self.rep_table)
        sql = '''SELECT DISTINCT table_name, uid
                 FROM %s
                 WHERE stamp < '%s'::timestamp with time zone
                 ORDER BY table_name;
              ''' % (table_name, timestamp)

        self._exec_sql(c, sql)
        attrs = c.fetchall()
        return attrs

    def clear_old_records(self, timestamp):
        table_name = self._table_name(self.rep_schema, self.rep_table)
        sql = '''DELETE FROM %s
                 WHERE stamp < '%s'::timestamp with time zone;
              ''' % (table_name, timestamp)

        self._exec_sql_and_commit(sql)
        self.logger.info('Old records removed.')
        return True

    def create_replog_table(self):
        schema = self.rep_schema
        table = self.rep_table
        table_name = self._table_name(schema, table)

        if self._table_exists(schema, table):
            self.logger.debug(
                '"%s" table already exists. Skipping creation.' % table_name)
            return True

        sql = '''CREATE TABLE %s (
                     table_name character varying(255) NOT NULL,
                     operation smallint NOT NULL,
                     stamp timestamp with time zone NOT NULL DEFAULT
                         ('now'::text)::timestamp(2) with time zone,
                     uid CHARACTER VARYING(50) NOT NULL)
              WITH (OIDS=FALSE);
              ALTER TABLE %s OWNER TO %s;
              COMMENT ON COLUMN %s.operation IS
                  '1 - DELETE, 2 - INSERT, 3 - UPDATE';
              ''' % (table_name, table_name, self.user, table_name)

        self._exec_sql_and_commit(sql)
        self.logger.info('Created table "%s".' % table_name)
        return True

    def populate_values(self, fields, values, field_list):
        out = u''
        for count, field_name in enumerate(field_list):
            field_defn = [f for f in fields if f[1] == field_name][0]
            field_type = field_defn[2]
            value = values[count]

            if field_type in ['text', 'varchar']:
                if value is not None:
                    out += u"'%s', " % self._quote_str(value)
                else:
                    out += u'NULL, '
            elif field_type == 'bool':
                if value is not None:
                    out += u'%s, ' % value
                else:
                    out += u'NULL, '
            elif field_type == 'uuid':
                if value is not None:
                    out += u"'%s', " % value
                else:
                    out += u'NULL, '
            elif self.re_is_integer.match(field_type) is not None or \
                    self.re_is_float.match(field_type) is not None:
                if value is not None:
                    out += '%s, ' % value
                else:
                    out += 'NULL, '
            elif field_type in ['numeric']:
                if value is not None:
                    out += u'%s, ' % value
                else:
                    out += u'NULL, '
            elif field_type in ['timestamp', 'timestamptz', 'date', 'time',
                                'interval']:
                if value is not None:
                    out += u"'%s', " % value
                else:
                    out += u'NULL, '
            elif field_type in ['geometry']:
                if value is not None:
                    out += u'%s, ' % value
                else:
                    out += u'NULL, '

        out = out[:-2]
        return out

    def _table_exists(self, schema, table):
        table_name = self._table_name(schema, table)

        tables = self.list_geotables(schema)
        if len([t for t in tables if t[0] == table]) > 0:
            self.logger.debug('Found "%s" table.' % table_name)
            return True
        else:
            self.logger.debug('Table "%s" not found.' % table_name)
            return False

    def _exec_sql(self, cursor, sql):
        try:
            self.logger.debug('Execute query: "%s"' % ' '.join(sql.split()))
            cursor.execute(sql)
        except psycopg2.Error, e:
            raise DbError(e.message, e.cursor.query)

    def _exec_sql_and_commit(self, sql):
        try:
            c = self.con.cursor()
            self._exec_sql(c, sql)
            self.con.commit()
        except DbError, e:
            self.logger.debug(e.message)
            self.con.rollback()
            raise

    def _quote(self, identifier):
        identifier = unicode(identifier)

        if self.re_ident_ok.match(identifier) is not None:
            return identifier

        return u'"%s"' % identifier.replace('"', '""')

    def _quote_str(self, txt):
        txt = unicode(txt)
        return txt.replace("'", "''")

    def _quote_field_list(self, field_list):
        quoted_fields = []
        for field in field_list:
            if field.startswith('encode') or field.startswith('ST_GeomFrom'):
                quoted_fields.append(field)
                continue
            quoted_fields.append('"%s"' % field)
        return quoted_fields

    def _table_name(self, schema, table):
        if not schema:
            return self._quote(table)
        else:
            return u'%s.%s' % (self._quote(schema), self._quote(table))

    def _create_message(self, table, ddl, sql, local_addr, url, error=None):
        msg = '<?xml version="1.0" encoding="UTF-8"?>\n'
        msg += '<soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"\n'
        msg += 'xmlns:wsa="http://www.w3.org/2005/08/addressing"\n'
        msg += 'xmlns:sv="urn:sm:interaction:v0.2">\n'
        msg += '<soap:Header>\n'
        msg += '<wsa:To>%s</wsa:To>\n' % url
        msg += '<wsa:From><wsa:Address>%s</wsa:Address></wsa:From>\n' % local_addr
        msg += '<wsa:MessageID>urn:uuid:%s</wsa:MessageID>\n' % uuid.uuid4()
        msg += '<wsa:Action>ISTC://SP.202.0001</wsa:Action>\n'
        msg += '</soap:Header><soap:Body>\n'
        msg += '<tbl>%s</tbl>\n' % table
        msg += '<ddl>%s</ddl>\n' % ddl
        msg += '<sql>%s</sql>\n' % sql
        msg += '<src>%s</src>\n' % local_addr
        msg += '<dst>%s</dst>\n' % url
        if error is None:
            msg += '<err></err>\n'
        else:
            msg += '<err>%s</err>\n' % error
        msg += '</soap:Body></soap:Envelope>'
        return msg


def register_table(host, port, dbname, user, passwd, full_table_name):
    logger.debug('register_table entered.')

    schema = full_table_name.split('.')[0]
    table = full_table_name.split('.')[1]

    db = PgDB(host, port, dbname, user, passwd)
    db.register_table(schema, table)
    logger.info('Table "%s" registered for replication.' % full_table_name)


def create_changesets(host, port, dbname, user, passwd, bus, bus_user,
                      bus_passwd, local_addr, boundary, url_field):
    logger.debug('create_changesets entered.')
    timestamp = datetime.datetime.now().isoformat()
    logger.debug('Process records for %s.' % timestamp)
    db = PgDB(host, port, dbname, user, passwd)
    db.prepare_changes(timestamp, boundary, url_field, bus, bus_user,
                       bus_passwd, local_addr)


def apply_changesets(host, port, dbname, user, passwd, directory, bus, bus_user,
                     bus_passwd):
    logger.debug('apply_changesets entered.')
    timestamp = datetime.datetime.now().isoformat()
    logger.debug('Process files for %s.' % timestamp)
    db = PgDB(host, port, dbname, user, passwd)
    db.apply_changes(directory, bus, bus_user, bus_passwd)


if __name__ == '__main__':
    fp = open(os.path.join('/var/run', pid_file), 'w')
    try:
        fcntl.lockf(fp, fcntl.LOCK_EX | fcntl.LOCK_NB)
    except IOError:
        sys.exit(0)

    logger.setLevel(logging.DEBUG)

    ch = logging.StreamHandler()
    ch.setLevel(logging.ERROR)

    formatter = logging.Formatter(
        '%(asctime)s %(name)s: %(levelname)s: %(message)s',
        datefmt='%b %d %H:%M:%S')
    ch.setFormatter(formatter)

    logger.addHandler(ch)

    parser = argparse.ArgumentParser(
        description='Replication of the PostgreSQL database.',
        epilog='Report bugs at bugtracker')

    parser.add_argument('-a', '--add', metavar='TABLE', dest='tableName',
        help='Register table TABLE for replication')
    parser.add_argument('-c', '--create', action='store_true',
        dest='createChangesets', help='Create changesets')
    parser.add_argument('-s', '--sync', action='store_true',
        dest='syncChangesets', help='Apply changesets to database')

    if len(sys.argv) <= 1:
        parser.print_usage()

    args = parser.parse_args()

    config_name = '/etc/pg_replica.conf'
    if not os.path.isfile(config_name):
        logger.critical('Configuration file "%s" not found.' % config_name)
        sys.exit(1)

    cfg = ConfigParser.SafeConfigParser(
        {'log_file': '/var/log/pg_replica.log',
         'log_level': 'debug'})

    cfg.read(config_name)
    log_file = cfg.get('logging', 'log_file')
    log_level = cfg.get('logging', 'log_level')
    num_level = getattr(logging, log_level.upper(), None)
    if not isinstance(num_level, int):
        num_level = 10

    fh = logging.FileHandler(log_file, encoding='utf-8')
    fh.setLevel(num_level)
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    logger.info('Start logging.')

    if cfg.has_section('connection'):
        host = cfg.get('connection', 'host')
        port = cfg.getint('connection', 'port')
        dbname = cfg.get('connection', 'database')
        user = cfg.get('connection', 'user')
        passwd = cfg.get('connection', 'password')
    else:
        logger.critical('Connection settings not found in config file.')
        sys.exit(1)

    if cfg.has_section('bus'):
        bus = cfg.get('bus', 'bus_address')
        bus_user = cfg.get('bus', 'user')
        bus_passwd = cfg.get('bus', 'password')
        local_addr = cfg.get('bus', 'local_address')
    else:
        logger.critical('Connection settings not found in config file.')
        sys.exit(1)

    if cfg.has_section('zones'):
        table_name = cfg.get('zones', 'table_name')
        field_name = cfg.get('zones', 'field_name')
    else:
        logger.critical('Helper table settings not found in config file.')
        sys.exit(1)

    if cfg.has_section('changes'):
        directory = cfg.get('changes', 'dir_name')
    else:
        logger.critical('Changesets directory not found in config file.')
        sys.exit(1)


    if args.tableName:
        register_table(host, port, dbname, user, passwd, args.tableName)
    elif args.createChangesets:
        create_changesets(host, port, dbname, user, passwd, bus, bus_user,
                          bus_passwd, local_addr, table_name, field_name)
    elif args.syncChangesets:
        apply_changesets(host, port, dbname, user, passwd, directory, bus,
                         bus_user, bus_passwd)

    logger.info('Stop logging.')
    logging.shutdown()
